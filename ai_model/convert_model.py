# Contenido corregido para: ai_model/convert_model.py

import tensorflow as tf
import os

print("ü§ñ Iniciando conversi√≥n a TensorFlow Lite...")

# Cargar el modelo H5 que entrenamos
MODEL_PATH = 'trained_model/model_v2_lstm.h5'
model = tf.keras.models.load_model(MODEL_PATH)
print("‚úÖ Modelo H5 cargado exitosamente.")

# Inicializar el conversor de TFLite
converter = tf.lite.TFLiteConverter.from_keras_model(model)

# --- LA CORRECCI√ìN CLAVE ---
# Le damos al convertidor las instrucciones que el propio error nos sugiri√≥.
# Esto le permite manejar las operaciones complejas de la LSTM.
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS, # Usa operaciones nativas de TFLite cuando sea posible
    tf.lite.OpsSet.SELECT_TF_OPS  # Y usa operaciones de TensorFlow cuando no haya un equivalente
]
converter._experimental_lower_tensor_list_ops = False
# --- FIN DE LA CORRECCI√ìN ---


# Aplicar optimizaciones para hacerlo a√∫n m√°s peque√±o y r√°pido
converter.optimizations = [tf.lite.Optimize.DEFAULT]

# Realizar la conversi√≥n
tflite_model = converter.convert()
print("‚úÖ Modelo convertido a formato TFLite.")

# Guardar el nuevo modelo .tflite
TFLITE_MODEL_PATH = 'trained_model/model_v2.tflite'
with open(TFLITE_MODEL_PATH, 'wb') as f:
    f.write(tflite_model)

print(f"\nüíæ ¬°√âxito! Modelo TFLite guardado en: {TFLITE_MODEL_PATH}")
original_size_kb = os.path.getsize(MODEL_PATH) / 1024
tflite_size_kb = len(tflite_model) / 1024
print(f"   - Tama√±o original (H5): {original_size_kb:.2f} KB")
print(f"   - Tama√±o nuevo (TFLite): {tflite_size_kb:.2f} KB")
print(f"   - Reducci√≥n de tama√±o: {(1 - tflite_size_kb / original_size_kb) * 100:.2f}%")